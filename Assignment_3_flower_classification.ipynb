{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLcWRu-jp7gM"
      },
      "source": [
        "# MIS 583 Assignment 3: Flower Classfication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSwr9MgZogRZ"
      },
      "source": [
        "Before we start, please put your name and ID in following format: <br>\n",
        "NAME, ?000000000   e.g. 陳琨翔, M094020003\n",
        "\n",
        "**Your Answer:**   \n",
        "Hi I'm XXX, XXXXXXXXXX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_MoQiztpxcK"
      },
      "source": [
        "## Flower Classification\n",
        "\n",
        "Image classification is a core and fundamental task in computer vision.\n",
        "\n",
        "In the assignment, you will implement a multi-class image classifier to recognize flowers.\n",
        "\n",
        "You will design and train a deep convolutional network from scratch to predict the class label of a flower image. This will help you gain experience with network design and get more familiar with PyTorch.\n",
        "\n",
        "**Please note that you’re not allowed to use a pre-trained model.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1NQv3Ey3cVS"
      },
      "source": [
        "## Kaggle Competition\n",
        "Kaggle is an online community of data scientists and machine learning practitioners. Kaggle allows users to find and publish data sets, explore and build models in a web-based data-science environment, work with other data scientists and machine learning engineers, and enter competitions to solve data science challenges.\n",
        "\n",
        "This assignment use kaggle to calculate your grade.  \n",
        "Please use this [**LINK**](https://www.kaggle.com/t/a16786b7da97419f9ba90b495dab08aa) to join the competition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giUId1Naqacs"
      },
      "source": [
        "##  Versions of used packages\n",
        "\n",
        "We will check PyTorch version to make sure everything work properly.\n",
        "\n",
        "We use `python 3.6.9`, `torch==1.6.0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vuw-gNvjqcYe",
        "outputId": "681f5ca0-1a15-4611-a979-76665ef366c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!python --version\n",
        "!pip freeze | grep torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n",
            "torch==1.6.0+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.3.1\n",
            "torchvision==0.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FydjP4MTWuL"
      },
      "source": [
        "## Error handling\n",
        "\n",
        "**RuntimeError: CUDA out of memory...**\n",
        "> 發生原因可能為讀取的 batch 過大或是記憶體未釋放乾淨。若縮小 batch size 後仍出現錯誤請按照以下步驟重新載入 colab。\n",
        "\n",
        "1. Click 「Runtime」\n",
        "2. Click 「Factor reset runtime」\n",
        "3. Click 「Reconnect」\n",
        "4. Reload all chunk\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhdbdJOsrbxL"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPoSgD83teTQ"
      },
      "source": [
        "We use [Flowers Recognition](https://www.kaggle.com/alxmamaev/flowers-recognition) dataset.\n",
        "This is collected by Alexander Mamaev.\n",
        "\n",
        "**Abstrct**  \n",
        "\n",
        "This dataset contains 4323 images of flowers.\n",
        "The data collection is based on the data flicr, google images, yandex images.\n",
        "You can use this datastet to recognize plants from the photo.\n",
        "\n",
        "The pictures are divided into five classes:\n",
        "+ daisy\n",
        "+ tulip\n",
        "+ rose\n",
        "+ sunflower\n",
        "+ dandelion\n",
        "\n",
        "For each class there are about 800 photos. Photos are not high resolution, about 320x240 pixels. Photos are not reduced to a single size, they have different proportions!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiMThsYeDa2O"
      },
      "source": [
        "## Get Data\n",
        "\n",
        "請先到共用雲端硬碟將檔案`flower_data.zip`，建立捷徑到自己的雲端硬碟中。\n",
        "\n",
        "> 操作步驟\n",
        "1. 點開雲端[連結](https://drive.google.com/file/d/1rTfeCpKXoQXI978QiTWC-AI1vwGvd5SU/view?usp=sharing)\n",
        "2. 點選右上角「新增雲端硬碟捷徑」\n",
        "3. 點選「我的雲端硬碟」\n",
        "4. 點選「新增捷徑」\n",
        "\n",
        "完成以上流程會在你的雲端硬碟中建立一個檔案的捷徑，接著我們在colab中取得權限即可使用。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBY0b6zxI0r9"
      },
      "source": [
        "執行此段後點選出現的連結，允許授權後，複製授權碼，貼在空格中後按下ENTER，即完成與雲端硬碟連結。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCXepUIVe5iJ"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqO8DiB6VRQZ"
      },
      "source": [
        "## Unzip Data\n",
        "\n",
        "解壓縮 `flower_data.zip` 後可以發現裡面有兩個資料夾和三個csv檔。\n",
        "\n",
        "+ `train` : 存有五個資料夾分別是五個種類的花，資料夾內為花的照片。\n",
        "+ `test` : 資料夾中為未分類之測試集照片。\n",
        "+ `train.csv` : 讀取 train data 的順序、路徑與圖片所屬花別。\n",
        "+ `val.csv` : 讀取 validate data 的順序、路徑與圖片所屬花別。\n",
        "+ `test.csv` : 讀取 test data 的順序、路徑。\n",
        "\n",
        "其中`train`的圖片3112張，`val`的圖片778章，`test`的圖片433張。\n",
        "\n",
        "注意: 若有另外設定存放在雲端硬碟中的路徑，請記得本處路徑也須做更動。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGCZQxZSfONu"
      },
      "source": [
        "!unzip -qq ./drive/My\\ Drive/flower_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYueKGdIHpho"
      },
      "source": [
        "## Loading the dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpG2DxEqHFD-"
      },
      "source": [
        "### Custom dataset\n",
        "\n",
        "繼承自定義資料集的框架 `torch.utils.data.Dataset`，主要實現 `__getitem__()` 和 `__len__()` 這兩個方法。\n",
        "\n",
        "常使用來做到設定資料位址、設定讀取方式、子資料集的標籤和轉換條件...等。\n",
        "\n",
        "See [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset) for more details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwUE1E83_Iw8"
      },
      "source": [
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "class FlowerData(torch.utils.data.Dataset):\n",
        "    def __init__(self, csv_file, mode='train', transform=None):\n",
        "\n",
        "        self.mode = mode # 'train', 'val' or 'test'\n",
        "        self.data_list = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(csv_file, newline='') as csvfile:\n",
        "            reader = csv.DictReader(csvfile)\n",
        "            for row in reader:\n",
        "                self.data_list.append(row['file_path'])\n",
        "                if mode != 'test':\n",
        "                    self.labels.append(row['label'])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        data = Image.open(self.data_list[index])\n",
        "        if self.transform is not None:\n",
        "            data = self.transform(data)\n",
        "        if self.mode == 'test':\n",
        "            return data\n",
        "        label = torch.tensor(int(self.labels[index]))\n",
        "\n",
        "        return data, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tQGLuVWnA-b"
      },
      "source": [
        "### Data augmentation\n",
        "\n",
        "Data augmentation are techniques used to increase the amount of data by adding slightly modified copies of already existing data or newly created synthetic data from existing data.\n",
        "\n",
        "Pytorch use `torchvision.transforms` to do data augmentation.\n",
        "[You can see all function here.](https://pytorch.org/docs/stable/torchvision/transforms.html)\n",
        "\n",
        "**NOTICE**: There are some operations may not be necessary for predict, so we should write one for train and one for others.\n",
        "\n",
        "(**Slide.07 page.49**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIv1VyHXVNTo"
      },
      "source": [
        "from torchvision import transforms\n",
        "# For TRAIN\n",
        "########################################################################\n",
        "#  TODO: use transforms.xxx method to do some data augmentation        #\n",
        "#  This one is for training, find the composition to get better result #\n",
        "########################################################################\n",
        "transforms_train = ...\n",
        "########################################################################\n",
        "#                           End of your code                           #\n",
        "########################################################################\n",
        "\n",
        "# For VAL, TEST\n",
        "########################################################################\n",
        "#  TODO: use transforms.xxx method to do some data augmentation        #\n",
        "#  This one is for validate and test,                                  #\n",
        "#  NOTICE some operation we usually not use in this part               #\n",
        "########################################################################\n",
        "transforms_test = ...\n",
        "########################################################################\n",
        "#                           End of your code                           #\n",
        "########################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rYptn_YJlFX"
      },
      "source": [
        "### Instantiate dataset\n",
        "\n",
        "Let's instantiate three `FlowerData` class.\n",
        "+ dataset_train: for training.\n",
        "+ dataset_val: for validation.\n",
        "+ dataset_test: for tesing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKjsKyHhZZc6"
      },
      "source": [
        "dataset_train = FlowerData('./data/train.csv', mode='train', transform=transforms_train)\n",
        "dataset_val = FlowerData('./data/val.csv', mode='val', transform=transforms_test)\n",
        "dataset_test = FlowerData('./data/test.csv', mode='test', transform=transforms_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAeQQEEISCJJ",
        "outputId": "d8a3ee5c-72d2-430e-ff29-3c21a01c83c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"The first image's shape in dataset_train :\", dataset_train.__getitem__(0)[0].size())\n",
        "print(\"There are\", dataset_train.__len__(), \"images in dataset_train.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The first image's shape in dataset_train : torch.Size([3, 112, 112])\n",
            "There are 3112 images in dataset_train.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vORA6qkfIj1U"
      },
      "source": [
        "### `DataLoader`\n",
        "\n",
        "`torch.utils.data.DataLoader` define how to sample from `dataset` and some other function like:\n",
        "+ `shuffle` : set to `True` to have the data reshuffled at every epoch\n",
        "+ `batch_size` : how many samples per batch to load\n",
        "\n",
        "See [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for more details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmgA5nYT3XQZ"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(dataset_train, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(dataset_val, batch_size=128, shuffle=False)\n",
        "test_loader = DataLoader(dataset_test, batch_size=128, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4atwzT3aPi3"
      },
      "source": [
        "Finally! We have made all data prepared.  \n",
        "Let's go develop our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87KYcWknS95z"
      },
      "source": [
        "# Implement CNN using PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH_4NKB9dsZ3"
      },
      "source": [
        "### Define a Convolutional Neural Network\n",
        "\n",
        "Try to design and train a deep convolutional network from scratch to predict the class label of a flower image.\n",
        "\n",
        "You can refer to last assignment about image_classifier, and try to go deep and use more method for better model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_HxxEfdO2Ss"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Your_CNN_Model(nn.Module):\n",
        "\tdef __init__(self):\n",
        "\t\tsuper().__init__()\n",
        "\t\t########################################################################\n",
        "\t\t#     TODO: use nn.xxx method to generate a CNN model part             #\n",
        "\t\t########################################################################\n",
        "\t\tself.conv = ... # You can change the variable name\n",
        "\t\t########################################################################\n",
        "\t\t#                           End of your code                           #\n",
        "\t\t########################################################################\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\tif not isinstance(x, torch.Tensor):\n",
        "\t\t\tx = torch.Tensor(x)\n",
        "\t\t########################################################################\n",
        "\t\t#     TODO: forward your model and get output                          #\n",
        "\t\t########################################################################\n",
        "\t\tout = ...\n",
        "\t\t########################################################################\n",
        "\t\t#                           End of your code                           #\n",
        "\t\t########################################################################\n",
        "\t\treturn out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP55C9Xjydws"
      },
      "source": [
        "model = Your_CNN_Model()\n",
        "model = model.cuda()\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83imqLRQ0v7M"
      },
      "source": [
        "We have made our model!  \n",
        "Next, PyTorch also provide many utility function(loss, optmizer...etc).  \n",
        "You can define them in one-line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtOkPO6Ga0Fw"
      },
      "source": [
        "### Define loss and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoePct00RIFY"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "################################################################################\n",
        "# TODO: Define loss and optmizer functions                                     #\n",
        "# Try any loss or optimizer function and learning rate to get better result    #\n",
        "# hint: torch.nn and torch.optim                                               #\n",
        "################################################################################\n",
        "criterion = ...\n",
        "optimizer = ...\n",
        "################################################################################\n",
        "#                               End of your code                               #\n",
        "################################################################################\n",
        "criterion = criterion.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zle9KuFcbwMP"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZFxE7Y9iLfl"
      },
      "source": [
        "#### Train function\n",
        "Let's define train function.  \n",
        "It will iterate input data 1 epoch and update model with optmizer.  \n",
        "Finally, calculate mean loss and total accuracy.\n",
        "\n",
        "Hint: [torch.max()](https://pytorch.org/docs/stable/generated/torch.max.html#torch-max)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM93brDshO6E"
      },
      "source": [
        "def train(input_data, model, criterion, optimizer):\n",
        "    '''\n",
        "    Argement:\n",
        "    input_data -- iterable data, typr torch.utils.data.Dataloader is prefer\n",
        "    model -- nn.Module, model contain forward to predict output\n",
        "    criterion -- loss function, used to evaluate goodness of model\n",
        "    optimizer -- optmizer function, method for weight updating\n",
        "    '''\n",
        "    model.train()\n",
        "    loss_list = []\n",
        "    total_count = 0\n",
        "    acc_count = 0\n",
        "    for i, data in enumerate(input_data, 0):\n",
        "        images, labels = data[0].cuda(), data[1].cuda()\n",
        "\n",
        "        ########################################################################\n",
        "        # TODO: Forward, backward and optimize                                 #\n",
        "        # 1. zero the parameter gradients                                      #\n",
        "        # 2. process input through the network                                 #\n",
        "        # 3. compute the loss                                                  #\n",
        "        # 4. propagate gradients back into the network’s parameters            #\n",
        "        # 5. Update the weights of the network                                 #\n",
        "        ########################################################################\n",
        "        pass\n",
        "        ########################################################################\n",
        "        #                           End of your code                           #\n",
        "        ########################################################################\n",
        "\n",
        "\n",
        "        ########################################################################\n",
        "        # TODO: Get the counts of correctly classified images                  #\n",
        "        # 1. get the model predicted result                                    #\n",
        "        # 2. sum the number of this batch predicted images                     #\n",
        "        # 3. sum the number of correctly classified                            #\n",
        "        # 4. save this batch's loss into loss_list                             #\n",
        "        # dimension of outputs: [batch_size, number of classes]                #\n",
        "        # Hint 1: use outputs.data to get no auto_grad                         #\n",
        "        # Hint 2: use torch.max()                                              #\n",
        "        ########################################################################\n",
        "        _, predicted = ...\n",
        "        total_count += ...\n",
        "        acc_count += ...\n",
        "        loss_list ...\n",
        "        ########################################################################\n",
        "        #                           End of your code                           #\n",
        "        ########################################################################\n",
        "\n",
        "    # Compute this epoch accuracy and loss\n",
        "    acc = acc_count / total_count\n",
        "    loss = sum(loss_list) / len(loss_list)\n",
        "    return acc, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmDy1GTq_H2a"
      },
      "source": [
        "#### Validate function\n",
        "Next part is validate function.  \n",
        "It works as training function without optmizer and weight-updating part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USzbBgGEoTRu"
      },
      "source": [
        "def val(input_data, model, criterion):\n",
        "    model.eval()\n",
        "\n",
        "    loss_list = []\n",
        "    total_count = 0\n",
        "    acc_count = 0\n",
        "    with torch.no_grad():\n",
        "        for data in input_data:\n",
        "            images, labels = data[0].cuda(), data[1].cuda()\n",
        "\n",
        "            ####################################################################\n",
        "            # TODO: Get the predicted result and loss                          #\n",
        "            # 1. process input through the network                             #\n",
        "            # 2. compute the loss                                              #\n",
        "            # 3. get the model predicted result                                #\n",
        "            # 4. get the counts of correctly classified images                 #\n",
        "            # 5. save this batch's loss into loss_list                         #\n",
        "            ####################################################################\n",
        "            pass\n",
        "\n",
        "            total_count += ...\n",
        "            acc_count += ...\n",
        "            loss_list ...\n",
        "            ####################################################################\n",
        "            #                         End of your code                         #\n",
        "            ####################################################################\n",
        "\n",
        "    acc = acc_count / total_count\n",
        "    loss = sum(loss_list) / len(loss_list)\n",
        "    return acc, loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knXu74jCiuxP"
      },
      "source": [
        "#### Training in a loop\n",
        "Call train and test function in a loop.  \n",
        "Take a break and wait."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcVulKkFJRtI"
      },
      "source": [
        "################################################################################\n",
        "# You can adjust those hyper parameters to loop for max_epochs times           #\n",
        "################################################################################\n",
        "max_epochs = 10\n",
        "log_interval = 2 # print acc and loss in per log_interval time\n",
        "################################################################################\n",
        "#                               End of your code                               #\n",
        "################################################################################\n",
        "train_acc_list = []\n",
        "train_loss_list = []\n",
        "val_acc_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    train_acc, train_loss = train(train_loader, model, criterion, optimizer)\n",
        "    val_acc, val_loss = val(val_loader, model, criterion)\n",
        "\n",
        "    train_acc_list.append(train_acc)\n",
        "    train_loss_list.append(train_loss)\n",
        "    val_acc_list.append(val_acc)\n",
        "    val_loss_list.append(val_loss)\n",
        "    if epoch % log_interval == 0:\n",
        "        print('=' * 20, 'Epoch', epoch, '=' * 20)\n",
        "        print('Train Acc: {:.6f} Train Loss: {:.6f}'.format(train_acc, train_loss))\n",
        "        print('  Val Acc: {:.6f}   Val Loss: {:.6f}'.format(val_acc, val_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5pW9zcKAN-2"
      },
      "source": [
        "#### Visualize accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ifzgfp7iq2m"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(range(len(train_loss_list)), train_loss_list)\n",
        "plt.plot(range(len(val_loss_list)), val_loss_list, c='r')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.title('Loss')\n",
        "plt.show()\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(range(len(train_acc_list)), train_acc_list)\n",
        "plt.plot(range(len(val_acc_list)), val_acc_list, c='r')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.title('Acc')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMYSgO5viYOk"
      },
      "source": [
        "### Predict Result\n",
        "\n",
        "預測`test`並將結果上傳至Kaggle。[**連結**](https://www.kaggle.com/t/a16786b7da97419f9ba90b495dab08aa)\n",
        "\n",
        "執行完畢此區的程式碼後，會將`test`預測完的結果存下來。\n",
        "\n",
        "上傳流程\n",
        "1. 點選左側選單最下方的資料夾圖示\n",
        "2. 右鍵「result.csv」\n",
        "3. 點選「Download」\n",
        "4. 至連結網頁點選「Submit Predictions」\n",
        "5. 將剛剛下載的檔案上傳\n",
        "6. 系統會計算並公布其中70%資料的正確率"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiyK25P6KXrn"
      },
      "source": [
        "def predict(input_data, model):\n",
        "    model.eval()\n",
        "    output_list = []\n",
        "    with torch.no_grad():\n",
        "        for data in input_data:\n",
        "            images = data.cuda()\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            output_list.extend(predicted.to('cpu').numpy().tolist())\n",
        "    return output_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0I0LN7HwpnsX"
      },
      "source": [
        "idx = 0\n",
        "output_csv = predict(test_loader, model)\n",
        "with open('result.csv', 'w', newline='') as csvFile:\n",
        "    writer = csv.DictWriter(csvFile, fieldnames=['Id', 'Category'])\n",
        "    writer.writeheader()\n",
        "    for result in output_csv:\n",
        "        idx+=1\n",
        "        writer.writerow({'Id':idx, 'Category':result})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XTB6EF6mH2Q"
      },
      "source": [
        "# Keep trying and write report\n",
        "\n",
        "持續調整模型、訓練方法、損失函數、優化器等，來訓練出更好的模型，並記錄使用不同參數得出的效果，以利後續 Report 的撰寫。\n",
        "\n",
        "大家加油！"
      ]
    }
  ]
}